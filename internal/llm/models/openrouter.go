package models

const (
	ProviderOpenRouter ModelProvider = "openrouter"

	// TODO: These models should probably live in deepseek.go. OpenRouter generally shouldn't define models.
	DeepSeekChatFree ModelID = "deepseek-chat-free"
	DeepSeekR1Free   ModelID = "deepseek-r1-free"
)

var OpenRouterModels = map[ModelID]Model{
	GPT41: {
		ID:                 GPT41,
		Name:               "GPT 4.1",
		Provider:           ProviderOpenRouter,
		APIModel:           "gpt-4.1",
		CostPer1MIn:        2.00,
		CostPer1MInCached:  0.50,
		CostPer1MOutCached: 0.0,
		CostPer1MOut:       8.00,
		ContextWindow:      1_047_576,
		DefaultMaxTokens:   20000,
	},
	GPT41Mini: {
		ID:                 GPT41Mini,
		Name:               "GPT 4.1 mini",
		Provider:           ProviderOpenRouter,
		APIModel:           "gpt-4.1",
		CostPer1MIn:        0.40,
		CostPer1MInCached:  0.10,
		CostPer1MOutCached: 0.0,
		CostPer1MOut:       1.60,
		ContextWindow:      200_000,
		DefaultMaxTokens:   20000,
	},
	GPT41Nano: {
		ID:                 GPT41Nano,
		Name:               "GPT 4.1 nano",
		Provider:           ProviderOpenRouter,
		APIModel:           "gpt-4.1-nano",
		CostPer1MIn:        0.10,
		CostPer1MInCached:  0.025,
		CostPer1MOutCached: 0.0,
		CostPer1MOut:       0.40,
		ContextWindow:      1_047_576,
		DefaultMaxTokens:   20000,
	},
	GPT45Preview: {
		ID:                 GPT45Preview,
		Name:               "GPT 4.5 preview",
		Provider:           ProviderOpenRouter,
		APIModel:           "gpt-4.5-preview",
		CostPer1MIn:        75.00,
		CostPer1MInCached:  37.50,
		CostPer1MOutCached: 0.0,
		CostPer1MOut:       150.00,
		ContextWindow:      128_000,
		DefaultMaxTokens:   15000,
	},
	GPT4o: {
		ID:                 GPT4o,
		Name:               "GPT 4o",
		Provider:           ProviderOpenRouter,
		APIModel:           "gpt-4o",
		CostPer1MIn:        2.50,
		CostPer1MInCached:  1.25,
		CostPer1MOutCached: 0.0,
		CostPer1MOut:       10.00,
		ContextWindow:      128_000,
		DefaultMaxTokens:   4096,
	},
	GPT4oMini: {
		ID:                 GPT4oMini,
		Name:               "GPT 4o mini",
		Provider:           ProviderOpenRouter,
		APIModel:           "gpt-4o-mini",
		CostPer1MIn:        0.15,
		CostPer1MInCached:  0.075,
		CostPer1MOutCached: 0.0,
		CostPer1MOut:       0.60,
		ContextWindow:      128_000,
	},
	O1: {
		ID:                 O1,
		Name:               "O1",
		Provider:           ProviderOpenRouter,
		APIModel:           "o1",
		CostPer1MIn:        15.00,
		CostPer1MInCached:  7.50,
		CostPer1MOutCached: 0.0,
		CostPer1MOut:       60.00,
		ContextWindow:      200_000,
		DefaultMaxTokens:   50000,
		CanReason:          true,
	},
	O1Pro: {
		ID:                 O1Pro,
		Name:               "o1 pro",
		Provider:           ProviderOpenRouter,
		APIModel:           "o1-pro",
		CostPer1MIn:        150.00,
		CostPer1MInCached:  0.0,
		CostPer1MOutCached: 0.0,
		CostPer1MOut:       600.00,
		ContextWindow:      200_000,
		DefaultMaxTokens:   50000,
		CanReason:          true,
	},
	O1Mini: {
		ID:                 O1Mini,
		Name:               "o1 mini",
		Provider:           ProviderOpenRouter,
		APIModel:           "o1-mini",
		CostPer1MIn:        1.10,
		CostPer1MInCached:  0.55,
		CostPer1MOutCached: 0.0,
		CostPer1MOut:       4.40,
		ContextWindow:      128_000,
		DefaultMaxTokens:   50000,
		CanReason:          true,
	},
	O3: {
		ID:                 O3,
		Name:               "o3",
		Provider:           ProviderOpenRouter,
		APIModel:           "o3",
		CostPer1MIn:        10.00,
		CostPer1MInCached:  2.50,
		CostPer1MOutCached: 0.0,
		CostPer1MOut:       40.00,
		ContextWindow:      200_000,
		CanReason:          true,
	},
	O3Mini: {
		ID:                 O3Mini,
		Name:               "o3 mini",
		Provider:           ProviderOpenRouter,
		APIModel:           "o3-mini",
		CostPer1MIn:        1.10,
		CostPer1MInCached:  0.55,
		CostPer1MOutCached: 0.0,
		CostPer1MOut:       4.40,
		ContextWindow:      200_000,
		DefaultMaxTokens:   50000,
		CanReason:          true,
	},
	O4Mini: {
		ID:                 O4Mini,
		Name:               "o4 mini",
		Provider:           ProviderOpenRouter,
		APIModel:           "o4-mini",
		CostPer1MIn:        1.10,
		CostPer1MInCached:  0.275,
		CostPer1MOutCached: 0.0,
		CostPer1MOut:       4.40,
		ContextWindow:      128_000,
		DefaultMaxTokens:   50000,
		CanReason:          true,
	},
	Gemini25Flash: {
		ID:                 Gemini25Flash,
		Name:               "Gemini 2.5 Flash",
		Provider:           ProviderOpenRouter,
		APIModel:           "google/gemini-2.5-flash-preview-04-17",
		CostPer1MIn:        0.15,
		CostPer1MInCached:  0,
		CostPer1MOutCached: 0,
		CostPer1MOut:       0.60,
		ContextWindow:      1000000,
		DefaultMaxTokens:   50000,
	},
	Gemini25: {
		ID:                 Gemini25,
		Name:               "Gemini 2.5 Pro",
		Provider:           ProviderOpenRouter,
		APIModel:           "google/gemini-2.5-pro-preview-03-25",
		CostPer1MIn:        1.25,
		CostPer1MInCached:  0,
		CostPer1MOutCached: 0,
		CostPer1MOut:       10,
		ContextWindow:      1000000,
		DefaultMaxTokens:   50000,
	},
	DeepSeekChatFree: {
		ID:                 DeepSeekChatFree,
		Name:               "DeepSeek Chat (Free)",
		Provider:           ProviderOpenRouter,
		APIModel:           "deepseek/deepseek-chat-v3-0324:free",
		CostPer1MIn:        0,
		CostPer1MInCached:  0,
		CostPer1MOutCached: 0,
		CostPer1MOut:       0,
		ContextWindow:      12800,
		DefaultMaxTokens:   50000,
	},
	DeepSeekR1Free: {
		ID:                 DeepSeekR1Free,
		Name:               "DeepSeek R1 (Free)",
		Provider:           ProviderOpenRouter,
		APIModel:           "deepseek/deepseek-r1:free",
		CostPer1MIn:        0,
		CostPer1MInCached:  0,
		CostPer1MOutCached: 0,
		CostPer1MOut:       0,
		ContextWindow:      164000,
		DefaultMaxTokens:   50000,
	},
}
